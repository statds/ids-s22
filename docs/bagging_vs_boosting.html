
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>9.4. Bagging versus Boosting &#8212; Introduction to Data Science, Spring 2022</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9.5. Support Vector Machines" href="svm.html" />
    <link rel="prev" title="9.3. Random Forests" href="randomforests.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/tricircle.pdf" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Data Science, Spring 2022</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   2. Markdown Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="prman.html">
   3. Project Management
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="refresh.html">
   4. Python Refreshment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scipy.html">
   5. SciPy for Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pandas.html">
   6. Data Manipulation with Pandas
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="visual.html">
   7. Visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="matplotlib.html">
     7.1. Matplotlib: Visualization with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="plotnine.html">
     7.2. Plotnine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cartopy.html">
     7.3. Cartopy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="gmplot.html">
     7.4. GM Plot
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="statmodels.html">
   8. Statistical Tests and Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="patsy.html">
     8.1. Describing Models with Patsy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tests.html">
     8.2. Hypothesis Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="models.html">
     8.3. Linear and Generalized Linear Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="supervised.html">
   9. Supervised Learning
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="decisiontrees.html">
     9.2. Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="randomforests.html">
     9.3. Random Forests
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     9.4. Bagging versus Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="svm.html">
     9.5. Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nearest_neighbor.html">
     9.16. K Nearest Neighbor
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="unsupervised.html">
   10. Unsupervised Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="k_means_clustering.html">
     10.1. K-means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="GMM.html">
     10.2. Gaussian Mixture Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="exercises.html">
   11. Exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fixedit.html">
   12. I Fixed It
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="back.html">
   13. Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/docs/bagging_vs_boosting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/bagging_vs_boosting.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/statds/ids-s22/master?urlpath=tree/notes/docs/bagging_vs_boosting.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bagging">
   9.4.1. Bagging
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest">
     9.4.1.1. Random Forest
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#boosting">
   9.4.2. Boosting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptive-boosting-adaboost">
     9.4.2.1. Adaptive Boosting (AdaBoost)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradient-boosting">
     9.4.2.2. Gradient Boosting
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stochastic-gradient-boosting">
       9.4.2.2.1. Stochastic gradient boosting
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#extreme-gradient-boosting">
       9.4.2.2.2. Extreme gradient boosting
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Bagging versus Boosting</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bagging">
   9.4.1. Bagging
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest">
     9.4.1.1. Random Forest
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#boosting">
   9.4.2. Boosting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptive-boosting-adaboost">
     9.4.2.1. Adaptive Boosting (AdaBoost)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradient-boosting">
     9.4.2.2. Gradient Boosting
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stochastic-gradient-boosting">
       9.4.2.2.1. Stochastic gradient boosting
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#extreme-gradient-boosting">
       9.4.2.2.2. Extreme gradient boosting
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="bagging-versus-boosting">
<h1><span class="section-number">9.4. </span>Bagging versus Boosting<a class="headerlink" href="#bagging-versus-boosting" title="Permalink to this headline">¶</a></h1>
<p>An ensemble method combines multiple individual models in order to
produce predictions with better properties. It has been reported that
an ensemble is often more accurate than any of the single member
in the ensemble <span id="id1">[<a class="reference internal" href="back.html#id2">Bühlmann, 2012</a>, <a class="reference internal" href="back.html#id5">Opitz and Maclin, 1999</a>]</span>.</p>
<p>The bias-variance tradeoff is the key motivation. Each single model
(learner) may have high bias or higher variance or both. An ensemble
method seeks to reduce bias and/or variance of such weak learners by
combining several of them together in order to create a strong learner
(or ensemble model) that achieves better performances.</p>
<div class="section" id="bagging">
<h2><span class="section-number">9.4.1. </span>Bagging<a class="headerlink" href="#bagging" title="Permalink to this headline">¶</a></h2>
<p>Bagging stands for bootstrap aggregation.
In bagging, a collection of bootstrap samples of the data in a
training dataset are generated; a model (e.g., decision tree;
regression) is fit to each of the bootstrap sample independently; the
predictions of all the members in the ensemble are aggregated (e.g.,
majority vote). Bagging reduces the variance of the final prediction
through aggregation.</p>
<div class="section" id="random-forest">
<h3><span class="section-number">9.4.1.1. </span>Random Forest<a class="headerlink" href="#random-forest" title="Permalink to this headline">¶</a></h3>
<p>Random forest is a bagging approach with decision trees as individual
ensemble members, except that the features used for each tree are a
random subsample of all the features. The purpose of resampling the
features it to make the trees less dependent and more robust to
missing data.</p>
<p>Tuning parameters for a random forest include:</p>
<ol class="simple">
<li><p>number of trees;</p></li>
<li><p>number of features;</p></li>
<li><p>tree depth.</p></li>
</ol>
</div>
</div>
<div class="section" id="boosting">
<h2><span class="section-number">9.4.2. </span>Boosting<a class="headerlink" href="#boosting" title="Permalink to this headline">¶</a></h2>
<p>Boostting is a sequential approach where the training of a model
learner at a given step applies to “residuals” from the model fitted
at the previous steps. This way, the current step improves on data
points where the cumulative performance is not good. Boosting produces
an ensemble model that in general less biased than the weak learners
that compose it.</p>
<p>Unlike bagging, boosting cannot be done in parallel.</p>
<p>Boosting methods differ on how they create and aggregate the weak
learners during the sequential process.</p>
<p>See <a class="reference external" href="https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205">Joseph Rocca’s
post</a>;
<a class="reference external" href="https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/">Jason Brownlee’s
blog</a>.</p>
<div class="section" id="adaptive-boosting-adaboost">
<h3><span class="section-number">9.4.2.1. </span>Adaptive Boosting (AdaBoost)<a class="headerlink" href="#adaptive-boosting-adaboost" title="Permalink to this headline">¶</a></h3>
<p>Adaptive boosting updates the weights attached to each of the training
dataset observations. The ensemble model is a weighted sum of the weak
learners. Instead of trying to solve it in one single shot (finding
all the coefficients and weak learners that give the best overall
additive model), an iterative optimisation process is
much more tractable, even if it can lead to a sub-optimal solution.</p>
<p>For illustration, consider a binary classification problem, with <span class="math notranslate nohighlight">\(N\)</span>
observations and a given family of weak models. To initialize, all the
observations have the same weights <span class="math notranslate nohighlight">\(1/N\)</span>. Repeat over each weak model:</p>
<ul class="simple">
<li><p>fit the best possible weak model with the current observations
weights;</p></li>
<li><p>compute the value of the update coefficient that is some kind of
scalar evaluation metric of the weak learner that indicates how much
this weak learner should be taken into account into the ensemble
model;</p></li>
<li><p>update the strong learner by adding the new weak learner multiplied
by its update coefficient;</p></li>
<li><p>compute new observations weights that
expresse which observations we would like to focus on at the next
iteration (weights of observations wrongly predicted by the
aggregated model increase and weights of the correctly predicted
observations decrease).</p></li>
</ul>
</div>
<div class="section" id="gradient-boosting">
<h3><span class="section-number">9.4.2.2. </span>Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Permalink to this headline">¶</a></h3>
<p>Gradient boosting updates the dataset in eaching step. It casts the
problem into a gradient descent one: at each iteration we fit a weak
learner to the negative gradients of the current fitting error
(pseudo-residuals) with respect to the current ensemble model. In the
regression setting, the negative gradient is the residual from the
current ensemble model.</p>
<p>For illustration, continue with the binary classification
problem. Initialize the pseudo-residuals as the observation outcomes.
Repeat over the following steps:</p>
<ul class="simple">
<li><p>fit the best possible weak learner to pseudo-residuals (approximate
the negative gradients with respect to the current strong learner);</p></li>
<li><p>compute the value of the optimal step size that defines by how much
we update the ensemble model in the direction of the new weak
learner;</p></li>
<li><p>update the ensemble model by adding the new weak learner multiplied
by the step size (make a step of gradient descent);</p></li>
<li><p>compute new pseudo-residuals that indicate, for each observation, in
which direction we would like to update next the ensemble model
predictions.</p></li>
</ul>
<p>Gradient boosting uses a gradient descent approach and can be easily
adapted to a large number of loss functions. It can be considered as a
generalization of adaboost to arbitrary differentiable loss functions.</p>
<div class="section" id="stochastic-gradient-boosting">
<h4><span class="section-number">9.4.2.2.1. </span>Stochastic gradient boosting<a class="headerlink" href="#stochastic-gradient-boosting" title="Permalink to this headline">¶</a></h4>
<p>Stochastic gradient boosting (SGD) is a stochastic version of gradient
boosting. At each iteration, a subsample of the training data is drawn
at random (without replacement) from the full training dataset. The
randomly selected subsample is then used, instead of the full sample,
to fit the base learner. It reduce the dependence between the trees
in the sequence in gradient boosting models.</p>
</div>
<div class="section" id="extreme-gradient-boosting">
<h4><span class="section-number">9.4.2.2.2. </span>Extreme gradient boosting<a class="headerlink" href="#extreme-gradient-boosting" title="Permalink to this headline">¶</a></h4>
<p>Extreme gradient boosting is a specific implementation of the gradient
boosting method which uses more accurate approximations to find the
best tree model. It employs a number of nifty tricks that make it
exceptionally successful, particularly with structured data.</p>
<ul class="simple">
<li><p>computing second-order gradients, i.e. second partial derivatives of
the loss function (similar to Newton’s method), which provides more
information about the direction of gradients and how to get to the
minimum of our loss function. While regular gradient boosting uses
the loss function of our base model (e.g. decision tree) as a proxy
for minimizing the error of the overall model, XGBoost uses the 2nd
order derivative as an approximation.</p></li>
<li><p>advanced regularization (L1 &amp; L2), which improves model
generalization.</p></li>
<li><p>parallelized.</p></li>
</ul>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="randomforests.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">9.3. </span>Random Forests</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="svm.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">9.5. </span>Support Vector Machines</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Jun Yan and students in STAT 5255/3255, Spring 2022<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>