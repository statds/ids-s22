
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>13.2. Decision Trees &#8212; Introduction to Data Science, Spring 2022</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="13.3. Random Forests" href="randomforests.html" />
    <link rel="prev" title="13. Supervised Learning" href="supervised.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/tricircle.pdf" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Data Science, Spring 2022</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   2. Markdown Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="prman.html">
   7. Project Management
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="refresh.html">
   8. Python Refreshment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scipy.html">
   9. SciPy for Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pandas.html">
   10. Data Manipulation with Pandas
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="visual.html">
   11. Visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="matplotlib.html">
     11.1. Matplotlib: Visualization with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basemap.html">
     11.2. Basemap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cartopy.html">
     11.3. Cartopy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="plotnine.html">
     11.4. Plotnine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="gmplot.html">
     11.5. GM Plot
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="statmodels.html">
   12. Statistical Tests and Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="patsy.html">
     12.1. Describing Models with Patsy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tests.html">
     12.2. Hypothesis Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="models.html">
     12.3. Linear and Generalized Linear Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="supervised.html">
   13. Supervised Learning
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     13.2. Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="randomforests.html">
     13.3. Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bagging_vs_boosting.html">
     13.4. Bagging versus Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="svm.html">
     13.5. Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nearest_neighbor.html">
     13.16. K Nearest Neighbor
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="k_means_clustering.html">
   14. K-means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="exercises.html">
   15. Exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fixedit.html">
   16. I Fixed It
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="back.html">
   17. Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/docs/decisiontrees.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/decisiontrees.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/statds/ids-s22/master?urlpath=tree/notes/docs/decisiontrees.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#concepts">
   13.2.1. Concepts
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm-formulation">
     13.2.1.1. Algorithm Formulation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metrics">
     13.2.1.2. Metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confusion-matrix">
     13.2.1.3. Confusion Matrix
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-classification-example">
   13.2.2. Simple Classification Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-cleaning">
   13.2.3. Data Cleaning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-decision-tree-model">
   13.2.4. Classification Decision Tree Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-decision-tree-model">
   13.2.5. Regression Decision Tree Model
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Decision Trees</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#concepts">
   13.2.1. Concepts
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm-formulation">
     13.2.1.1. Algorithm Formulation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metrics">
     13.2.1.2. Metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confusion-matrix">
     13.2.1.3. Confusion Matrix
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-classification-example">
   13.2.2. Simple Classification Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-cleaning">
   13.2.3. Data Cleaning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-decision-tree-model">
   13.2.4. Classification Decision Tree Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-decision-tree-model">
   13.2.5. Regression Decision Tree Model
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="decision-trees">
<span id="trees"></span><h1><span class="section-number">13.2. </span>Decision Trees<a class="headerlink" href="#decision-trees" title="Permalink to this headline">¶</a></h1>
<p>Decision trees are a predictive modeling approach that uses probability trees to either predict a continous value or predict a classification that the data fits into.</p>
<p><strong>Pros:</strong></p>
<ul class="simple">
<li><p>Easy to understand and visualize</p></li>
<li><p>Easy to figure out why the model is making a certain prediction</p></li>
<li><p>Doesn’t need as much data preparation as other prediction methods</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul class="simple">
<li><p>Sometimes decision trees can get too complex and overfit the data</p></li>
<li><p>Small variations in the data could cause different trees to be created which can drastically change the model’s output</p></li>
</ul>
<div class="section" id="concepts">
<h2><span class="section-number">13.2.1. </span>Concepts<a class="headerlink" href="#concepts" title="Permalink to this headline">¶</a></h2>
<p>The goal of a decision tree algorithm to create a model that predicts the value
of a target variable by learning simple decision rules inferred from the data
features. A tree can be seen as a piecewise constant approximation.</p>
<div class="section" id="algorithm-formulation">
<h3><span class="section-number">13.2.1.1. </span>Algorithm Formulation<a class="headerlink" href="#algorithm-formulation" title="Permalink to this headline">¶</a></h3>
<p>At a given node, find the best split that minimizes some impurity or loss
measure <span class="math notranslate nohighlight">\(H\)</span> after the split. Let <span class="math notranslate nohighlight">\(Q_m\)</span> be the data at node <span class="math notranslate nohighlight">\(m\)</span> with sample size
<span class="math notranslate nohighlight">\(n_m\)</span>. Let <span class="math notranslate nohighlight">\(\theta\)</span> be a candidate split (which may consists of a candidate
threshold for candidate feature).  Suppose that after the split, <span class="math notranslate nohighlight">\(Q_{m,l}\)</span> is
the left node data with sample size <span class="math notranslate nohighlight">\(n_{m,l}\)</span> and <span class="math notranslate nohighlight">\(Q_{m,r}\)</span> is the right node
data with sample size <span class="math notranslate nohighlight">\(n_{m,r}\)</span>. The quality of the split is measured by</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
G(Q_m, \theta) = \frac{n_{m, l}}{n_m} H(Q_{m, l}(\theta))
 + \frac{n_{m,r}}{n_m} H(Q_{m, r}(\theta)).
\end{equation*}\]</div>
<p>The algorithm set</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\theta^* = \arg\min_{\theta} G(Q_m, \theta).
\end{equation*}\]</div>
<p>Recursively find the best split for each child node.</p>
<ul class="simple">
<li><p>Stopping: until a the maximum tree depth is reached or all node sample size is
below a preset threshold.</p></li>
<li><p>Pruning: reduces the complexity of the final classifier, and hence improves
predictive accuracy by the reduction of overfitting.</p></li>
</ul>
</div>
<div class="section" id="metrics">
<h3><span class="section-number">13.2.1.2. </span>Metrics<a class="headerlink" href="#metrics" title="Permalink to this headline">¶</a></h3>
<p>See <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> documentation for <a class="reference external" href="https://scikit-learn.org/stable/modules/tree.html#classification-criteria">details</a>.</p>
<ul class="simple">
<li><p>Classification</p>
<ul>
<li><p>Gini<br />
$<span class="math notranslate nohighlight">\(H(Q_m) = \sum_{k=1} p_{mk} (1 - p_{mk})\)</span>$</p></li>
<li><p>Entropy
$<span class="math notranslate nohighlight">\(H(Q_m) = - \sum p_{mk} \log p_{mk}\)</span>$</p></li>
<li><p>Misclassification
$<span class="math notranslate nohighlight">\(H(Q_m) = 1 - \max_k p_{mk}\)</span>$</p></li>
</ul>
</li>
<li><p>Regression</p>
<ul>
<li><p>Mean squared error</p></li>
<li><p>Half Poisson deviance (for count targets)</p></li>
<li><p>Mean absolute error (slower than MSE; more robust)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="confusion-matrix">
<h3><span class="section-number">13.2.1.3. </span>Confusion Matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">¶</a></h3>
<p>See <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> example for
<a class="reference external" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html?highlight=confusion">details</a>.</p>
<p>See definitions on <a class="reference external" href="https://en.wikipedia.org/wiki/Confusion_matrix">Wiki</a>.</p>
<p>A confusion matrix is a matrix layout of the results of a classification
algorithm, where each row of the matrix represents the instances in an actual
class while each column represents the instances in a predicted class, or vice
versa.</p>
<ul class="simple">
<li><p>True positive (TP)</p></li>
<li><p>False positive (FP)</p></li>
<li><p>True negative (TN)</p></li>
<li><p>False negative (FN)</p></li>
</ul>
<p>Metrics for evaluating classification:</p>
<ul class="simple">
<li><p>Precision:
$<span class="math notranslate nohighlight">\(\frac{\text{TP}}{\text{TP} + \text{FP}}\)</span>$</p></li>
<li><p>Recall (sensitivity):
$<span class="math notranslate nohighlight">\(\frac{\textt{TP}}{\text{TP} + \text{FP}}\)</span>$</p></li>
<li><p>F-beta score:
$<span class="math notranslate nohighlight">\((1 + \beta^2) \frac{1}{\frac{\beta^2}{\text{recall}} +
\frac{1}{\text{recision}}}\)</span><span class="math notranslate nohighlight">\(
where \)</span>\beta<span class="math notranslate nohighlight">\( means that recall is considered \)</span>\beta<span class="math notranslate nohighlight">\( times as important as
precision. When \)</span>\beta = 1$, the two are considered equally important.</p></li>
</ul>
<p>From Wiki:</p>
<blockquote>
<div><p>In a classification task, a precision score of 1.0 for a class C means that
every item labelled as belonging to class C does indeed belong to class C (but
says nothing about the number of items from class C that were not labelled
correctly) whereas a recall of 1.0 means that every item from class C was
labelled as belonging to class C (but says nothing about how many items from
other classes were incorrectly also labelled as belonging to class C).</p>
</div></blockquote>
</div>
</div>
<div class="section" id="simple-classification-example">
<h2><span class="section-number">13.2.2. </span>Simple Classification Example<a class="headerlink" href="#simple-classification-example" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## configure the inline figures to of svg format</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_formats = [&#39;svg&#39;]

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Text(0.5, 0.9166666666666666, &#39;X[2] &lt;= 2.45\ngini = 0.667\nsamples = 150\nvalue = [50, 50, 50]&#39;),
 Text(0.4230769230769231, 0.75, &#39;gini = 0.0\nsamples = 50\nvalue = [50, 0, 0]&#39;),
 Text(0.5769230769230769, 0.75, &#39;X[3] &lt;= 1.75\ngini = 0.5\nsamples = 100\nvalue = [0, 50, 50]&#39;),
 Text(0.3076923076923077, 0.5833333333333334, &#39;X[2] &lt;= 4.95\ngini = 0.168\nsamples = 54\nvalue = [0, 49, 5]&#39;),
 Text(0.15384615384615385, 0.4166666666666667, &#39;X[3] &lt;= 1.65\ngini = 0.041\nsamples = 48\nvalue = [0, 47, 1]&#39;),
 Text(0.07692307692307693, 0.25, &#39;gini = 0.0\nsamples = 47\nvalue = [0, 47, 0]&#39;),
 Text(0.23076923076923078, 0.25, &#39;gini = 0.0\nsamples = 1\nvalue = [0, 0, 1]&#39;),
 Text(0.46153846153846156, 0.4166666666666667, &#39;X[3] &lt;= 1.55\ngini = 0.444\nsamples = 6\nvalue = [0, 2, 4]&#39;),
 Text(0.38461538461538464, 0.25, &#39;gini = 0.0\nsamples = 3\nvalue = [0, 0, 3]&#39;),
 Text(0.5384615384615384, 0.25, &#39;X[0] &lt;= 6.95\ngini = 0.444\nsamples = 3\nvalue = [0, 2, 1]&#39;),
 Text(0.46153846153846156, 0.08333333333333333, &#39;gini = 0.0\nsamples = 2\nvalue = [0, 2, 0]&#39;),
 Text(0.6153846153846154, 0.08333333333333333, &#39;gini = 0.0\nsamples = 1\nvalue = [0, 0, 1]&#39;),
 Text(0.8461538461538461, 0.5833333333333334, &#39;X[2] &lt;= 4.85\ngini = 0.043\nsamples = 46\nvalue = [0, 1, 45]&#39;),
 Text(0.7692307692307693, 0.4166666666666667, &#39;X[0] &lt;= 5.95\ngini = 0.444\nsamples = 3\nvalue = [0, 1, 2]&#39;),
 Text(0.6923076923076923, 0.25, &#39;gini = 0.0\nsamples = 1\nvalue = [0, 1, 0]&#39;),
 Text(0.8461538461538461, 0.25, &#39;gini = 0.0\nsamples = 2\nvalue = [0, 0, 2]&#39;),
 Text(0.9230769230769231, 0.4166666666666667, &#39;gini = 0.0\nsamples = 43\nvalue = [0, 0, 43]&#39;)]
</pre></div>
</div>
<img alt="../_images/decisiontrees_1_1.svg" src="../_images/decisiontrees_1_1.svg" /></div>
</div>
</div>
<div class="section" id="data-cleaning">
<h2><span class="section-number">13.2.3. </span>Data Cleaning<a class="headerlink" href="#data-cleaning" title="Permalink to this headline">¶</a></h2>
<p>Import data and add a binary column for if a person was injured or not</p>
<p>Can’t use strings in decision trees so to fix this we can change each borough to a number
EX: Bronx = 1, Brooklyn = 2</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">nyc_collisions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/nyc_mv_collisions_202201.csv&quot;</span><span class="p">)</span>

<span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;CRASH TIME&quot;</span><span class="p">]]</span>
<span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]]</span>

<span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;injury_binary&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;NUMBER OF PERSONS INJURED&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span><span class="o">&gt;</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;num_borough&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;BOROUGH&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="s2">&quot;BRONX&quot;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;num_borough&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;BOROUGH&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="s2">&quot;BROOKLYN&quot;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;num_borough&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;BOROUGH&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="s2">&quot;QUEENS&quot;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;num_borough&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;BOROUGH&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">4</span> <span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="s2">&quot;MANHATTAN&quot;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;num_borough&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="s2">&quot;BOROUGH&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">5</span> <span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="s2">&quot;STATEN ISLAND&quot;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">nyc_collisions</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;NUMBER OF PERSONS KILLED&quot;</span><span class="p">:</span> <span class="s2">&quot;num_ppl_killed&quot;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nyc_collisions</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;NUMBER OF PERSONS INJURED&quot;</span><span class="p">:</span> <span class="s2">&quot;num_ppl_injured&quot;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>



<span class="n">nyc_collisions</span><span class="p">[</span><span class="s1">&#39;injury_binary&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    5311
1    2348
Name: injury_binary, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="classification-decision-tree-model">
<h2><span class="section-number">13.2.4. </span>Classification Decision Tree Model<a class="headerlink" href="#classification-decision-tree-model" title="Permalink to this headline">¶</a></h2>
<p>Select columns to use in our decision tree model.</p>
<p>Don’t want to use columns such as number of pedestrians injured because that heavily affects our target variable</p>
<p>We also split our dataset into a training set and a test set to avoid overfitting the data</p>
<p>We are trying to predict if someone was injured or not in a crash using all of the columns in <code class="docutils literal notranslate"><span class="pre">feature_cols</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="s1">&#39;num_borough&#39;</span><span class="p">,</span> <span class="s1">&#39;NUMBER OF MOTORIST KILLED&#39;</span><span class="p">,</span>
                <span class="s1">&#39;NUMBER OF CYCLIST KILLED&#39;</span><span class="p">,</span>
                <span class="s1">&#39;NUMBER OF PEDESTRIANS KILLED&#39;</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">]</span> <span class="c1"># Features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="o">.</span><span class="n">injury_binary</span> <span class="c1"># Target variable</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span> <span class="c1"># 80% training and 20% test</span>
</pre></div>
</div>
</div>
</div>
<p>We then set up our decision tree and use it to predict on the test set. This example is a classification
example so it will predict a 0 or 1 based on if someone was injured or not in the crash (1=injured)</p>
<p>We then can print out the accuracy of our model and a confusion matrix to see its predictions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Train Decision Tree Classifer</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1">#Predict the response for test dataset</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.6977806788511749
[[1064    3]
 [ 460    5]]
</pre></div>
</div>
</div>
</div>
<p>We can plot this model using the sklearn plotting function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Text(0.6271067415730337, 0.9583333333333334, &#39;X[0] &lt;= 16.5\ngini = 0.426\nsamples = 6127\nvalue = [4244, 1883]&#39;),
 Text(0.46207865168539325, 0.875, &#39;X[2] &lt;= 0.5\ngini = 0.405\nsamples = 4226\nvalue = [3035, 1191]&#39;),
 Text(0.351123595505618, 0.7916666666666666, &#39;X[1] &lt;= 2.5\ngini = 0.404\nsamples = 4222\nvalue = [3034, 1188]&#39;),
 Text(0.19662921348314608, 0.7083333333333334, &#39;X[0] &lt;= 5.5\ngini = 0.403\nsamples = 4110\nvalue = [2962, 1148]&#39;),
 Text(0.1348314606741573, 0.625, &#39;X[0] &lt;= 4.5\ngini = 0.386\nsamples = 940\nvalue = [694, 246]&#39;),
 Text(0.11235955056179775, 0.5416666666666666, &#39;X[0] &lt;= 3.5\ngini = 0.391\nsamples = 792\nvalue = [581, 211]&#39;),
 Text(0.0898876404494382, 0.4583333333333333, &#39;X[0] &lt;= 2.5\ngini = 0.385\nsamples = 641\nvalue = [474, 167]&#39;),
 Text(0.06741573033707865, 0.375, &#39;X[0] &lt;= 1.5\ngini = 0.393\nsamples = 535\nvalue = [391, 144]&#39;),
 Text(0.0449438202247191, 0.2916666666666667, &#39;X[0] &lt;= 0.5\ngini = 0.389\nsamples = 405\nvalue = [298, 107]&#39;),
 Text(0.02247191011235955, 0.20833333333333334, &#39;gini = 0.397\nsamples = 271\nvalue = [197, 74]&#39;),
 Text(0.06741573033707865, 0.20833333333333334, &#39;gini = 0.371\nsamples = 134\nvalue = [101, 33]&#39;),
 Text(0.0898876404494382, 0.2916666666666667, &#39;gini = 0.407\nsamples = 130\nvalue = [93, 37]&#39;),
 Text(0.11235955056179775, 0.375, &#39;gini = 0.34\nsamples = 106\nvalue = [83, 23]&#39;),
 Text(0.1348314606741573, 0.4583333333333333, &#39;gini = 0.413\nsamples = 151\nvalue = [107, 44]&#39;),
 Text(0.15730337078651685, 0.5416666666666666, &#39;gini = 0.361\nsamples = 148\nvalue = [113, 35]&#39;),
 Text(0.25842696629213485, 0.625, &#39;X[0] &lt;= 8.5\ngini = 0.407\nsamples = 3170\nvalue = [2268, 902]&#39;),
 Text(0.20224719101123595, 0.5416666666666666, &#39;X[4] &lt;= 0.5\ngini = 0.437\nsamples = 820\nvalue = [556, 264]&#39;),
 Text(0.1797752808988764, 0.4583333333333333, &#39;X[0] &lt;= 7.5\ngini = 0.437\nsamples = 818\nvalue = [554, 264]&#39;),
 Text(0.15730337078651685, 0.375, &#39;X[0] &lt;= 6.5\ngini = 0.431\nsamples = 461\nvalue = [316, 145]&#39;),
 Text(0.1348314606741573, 0.2916666666666667, &#39;gini = 0.437\nsamples = 223\nvalue = [151, 72]&#39;),
 Text(0.1797752808988764, 0.2916666666666667, &#39;gini = 0.425\nsamples = 238\nvalue = [165, 73]&#39;),
 Text(0.20224719101123595, 0.375, &#39;gini = 0.444\nsamples = 357\nvalue = [238, 119]&#39;),
 Text(0.2247191011235955, 0.4583333333333333, &#39;gini = 0.0\nsamples = 2\nvalue = [2, 0]&#39;),
 Text(0.3146067415730337, 0.5416666666666666, &#39;X[0] &lt;= 10.5\ngini = 0.396\nsamples = 2350\nvalue = [1712, 638]&#39;),
 Text(0.2696629213483146, 0.4583333333333333, &#39;X[0] &lt;= 9.5\ngini = 0.335\nsamples = 516\nvalue = [406, 110]&#39;),
 Text(0.24719101123595505, 0.375, &#39;gini = 0.335\nsamples = 263\nvalue = [207, 56]&#39;),
 Text(0.29213483146067415, 0.375, &#39;gini = 0.336\nsamples = 253\nvalue = [199, 54]&#39;),
 Text(0.3595505617977528, 0.4583333333333333, &#39;X[0] &lt;= 15.5\ngini = 0.41\nsamples = 1834\nvalue = [1306, 528]&#39;),
 Text(0.33707865168539325, 0.375, &#39;X[0] &lt;= 14.5\ngini = 0.416\nsamples = 1476\nvalue = [1040, 436]&#39;),
 Text(0.3146067415730337, 0.2916666666666667, &#39;X[0] &lt;= 12.5\ngini = 0.409\nsamples = 1132\nvalue = [808, 324]&#39;),
 Text(0.2696629213483146, 0.20833333333333334, &#39;X[0] &lt;= 11.5\ngini = 0.422\nsamples = 520\nvalue = [363, 157]&#39;),
 Text(0.24719101123595505, 0.125, &#39;gini = 0.404\nsamples = 256\nvalue = [184, 72]&#39;),
 Text(0.29213483146067415, 0.125, &#39;gini = 0.437\nsamples = 264\nvalue = [179, 85]&#39;),
 Text(0.3595505617977528, 0.20833333333333334, &#39;X[0] &lt;= 13.5\ngini = 0.397\nsamples = 612\nvalue = [445, 167]&#39;),
 Text(0.33707865168539325, 0.125, &#39;gini = 0.379\nsamples = 256\nvalue = [191, 65]&#39;),
 Text(0.38202247191011235, 0.125, &#39;gini = 0.409\nsamples = 356\nvalue = [254, 102]&#39;),
 Text(0.3595505617977528, 0.2916666666666667, &#39;gini = 0.439\nsamples = 344\nvalue = [232, 112]&#39;),
 Text(0.38202247191011235, 0.375, &#39;gini = 0.382\nsamples = 358\nvalue = [266, 92]&#39;),
 Text(0.5056179775280899, 0.7083333333333334, &#39;X[0] &lt;= 3.5\ngini = 0.459\nsamples = 112\nvalue = [72, 40]&#39;),
 Text(0.449438202247191, 0.625, &#39;X[0] &lt;= 2.5\ngini = 0.5\nsamples = 8\nvalue = [4, 4]&#39;),
 Text(0.42696629213483145, 0.5416666666666666, &#39;X[0] &lt;= 0.5\ngini = 0.444\nsamples = 6\nvalue = [4, 2]&#39;),
 Text(0.4044943820224719, 0.4583333333333333, &#39;gini = 0.5\nsamples = 2\nvalue = [1, 1]&#39;),
 Text(0.449438202247191, 0.4583333333333333, &#39;X[0] &lt;= 1.5\ngini = 0.375\nsamples = 4\nvalue = [3, 1]&#39;),
 Text(0.42696629213483145, 0.375, &#39;gini = 0.0\nsamples = 1\nvalue = [1, 0]&#39;),
 Text(0.47191011235955055, 0.375, &#39;gini = 0.444\nsamples = 3\nvalue = [2, 1]&#39;),
 Text(0.47191011235955055, 0.5416666666666666, &#39;gini = 0.0\nsamples = 2\nvalue = [0, 2]&#39;),
 Text(0.5617977528089888, 0.625, &#39;X[0] &lt;= 8.5\ngini = 0.453\nsamples = 104\nvalue = [68, 36]&#39;),
 Text(0.5168539325842697, 0.5416666666666666, &#39;X[0] &lt;= 4.5\ngini = 0.405\nsamples = 39\nvalue = [28, 11]&#39;),
 Text(0.4943820224719101, 0.4583333333333333, &#39;gini = 0.0\nsamples = 2\nvalue = [2, 0]&#39;),
 Text(0.5393258426966292, 0.4583333333333333, &#39;X[0] &lt;= 5.5\ngini = 0.418\nsamples = 37\nvalue = [26, 11]&#39;),
 Text(0.5168539325842697, 0.375, &#39;gini = 0.444\nsamples = 6\nvalue = [4, 2]&#39;),
 Text(0.5617977528089888, 0.375, &#39;X[0] &lt;= 7.5\ngini = 0.412\nsamples = 31\nvalue = [22, 9]&#39;),
 Text(0.5393258426966292, 0.2916666666666667, &#39;X[0] &lt;= 6.5\ngini = 0.408\nsamples = 14\nvalue = [10, 4]&#39;),
 Text(0.5168539325842697, 0.20833333333333334, &#39;gini = 0.408\nsamples = 7\nvalue = [5, 2]&#39;),
 Text(0.5617977528089888, 0.20833333333333334, &#39;gini = 0.408\nsamples = 7\nvalue = [5, 2]&#39;),
 Text(0.5842696629213483, 0.2916666666666667, &#39;gini = 0.415\nsamples = 17\nvalue = [12, 5]&#39;),
 Text(0.6067415730337079, 0.5416666666666666, &#39;X[0] &lt;= 9.5\ngini = 0.473\nsamples = 65\nvalue = [40, 25]&#39;),
 Text(0.5842696629213483, 0.4583333333333333, &#39;gini = 0.5\nsamples = 8\nvalue = [4, 4]&#39;),
 Text(0.6292134831460674, 0.4583333333333333, &#39;X[0] &lt;= 10.5\ngini = 0.465\nsamples = 57\nvalue = [36, 21]&#39;),
 Text(0.6067415730337079, 0.375, &#39;gini = 0.0\nsamples = 3\nvalue = [3, 0]&#39;),
 Text(0.651685393258427, 0.375, &#39;X[0] &lt;= 11.5\ngini = 0.475\nsamples = 54\nvalue = [33, 21]&#39;),
 Text(0.6292134831460674, 0.2916666666666667, &#39;gini = 0.5\nsamples = 12\nvalue = [6, 6]&#39;),
 Text(0.6741573033707865, 0.2916666666666667, &#39;X[0] &lt;= 14.5\ngini = 0.459\nsamples = 42\nvalue = [27, 15]&#39;),
 Text(0.6292134831460674, 0.20833333333333334, &#39;X[0] &lt;= 13.5\ngini = 0.413\nsamples = 24\nvalue = [17, 7]&#39;),
 Text(0.6067415730337079, 0.125, &#39;X[0] &lt;= 12.5\ngini = 0.444\nsamples = 15\nvalue = [10, 5]&#39;),
 Text(0.5842696629213483, 0.041666666666666664, &#39;gini = 0.444\nsamples = 9\nvalue = [6, 3]&#39;),
 Text(0.6292134831460674, 0.041666666666666664, &#39;gini = 0.444\nsamples = 6\nvalue = [4, 2]&#39;),
 Text(0.651685393258427, 0.125, &#39;gini = 0.346\nsamples = 9\nvalue = [7, 2]&#39;),
 Text(0.7191011235955056, 0.20833333333333334, &#39;X[0] &lt;= 15.5\ngini = 0.494\nsamples = 18\nvalue = [10, 8]&#39;),
 Text(0.6966292134831461, 0.125, &#39;gini = 0.496\nsamples = 11\nvalue = [6, 5]&#39;),
 Text(0.7415730337078652, 0.125, &#39;gini = 0.49\nsamples = 7\nvalue = [4, 3]&#39;),
 Text(0.5730337078651685, 0.7916666666666666, &#39;X[0] &lt;= 7.5\ngini = 0.375\nsamples = 4\nvalue = [1, 3]&#39;),
 Text(0.550561797752809, 0.7083333333333334, &#39;gini = 0.0\nsamples = 3\nvalue = [0, 3]&#39;),
 Text(0.5955056179775281, 0.7083333333333334, &#39;gini = 0.0\nsamples = 1\nvalue = [1, 0]&#39;),
 Text(0.7921348314606742, 0.875, &#39;X[0] &lt;= 18.5\ngini = 0.463\nsamples = 1901\nvalue = [1209, 692]&#39;),
 Text(0.6853932584269663, 0.7916666666666666, &#39;X[0] &lt;= 17.5\ngini = 0.478\nsamples = 722\nvalue = [437, 285]&#39;),
 Text(0.6404494382022472, 0.7083333333333334, &#39;X[1] &lt;= 2.5\ngini = 0.459\nsamples = 378\nvalue = [243, 135]&#39;),
 Text(0.6179775280898876, 0.625, &#39;gini = 0.456\nsamples = 367\nvalue = [238, 129]&#39;),
 Text(0.6629213483146067, 0.625, &#39;gini = 0.496\nsamples = 11\nvalue = [5, 6]&#39;),
 Text(0.7303370786516854, 0.7083333333333334, &#39;X[1] &lt;= 2.5\ngini = 0.492\nsamples = 344\nvalue = [194, 150]&#39;),
 Text(0.7078651685393258, 0.625, &#39;X[4] &lt;= 0.5\ngini = 0.49\nsamples = 329\nvalue = [188, 141]&#39;),
 Text(0.6853932584269663, 0.5416666666666666, &#39;gini = 0.489\nsamples = 328\nvalue = [188, 140]&#39;),
 Text(0.7303370786516854, 0.5416666666666666, &#39;gini = 0.0\nsamples = 1\nvalue = [0, 1]&#39;),
 Text(0.7528089887640449, 0.625, &#39;gini = 0.48\nsamples = 15\nvalue = [6, 9]&#39;),
 Text(0.898876404494382, 0.7916666666666666, &#39;X[1] &lt;= 2.5\ngini = 0.452\nsamples = 1179\nvalue = [772, 407]&#39;),
 Text(0.8426966292134831, 0.7083333333333334, &#39;X[4] &lt;= 0.5\ngini = 0.456\nsamples = 1150\nvalue = [746, 404]&#39;),
 Text(0.8202247191011236, 0.625, &#39;X[0] &lt;= 19.5\ngini = 0.456\nsamples = 1147\nvalue = [743, 404]&#39;),
 Text(0.7752808988764045, 0.5416666666666666, &#39;X[2] &lt;= 0.5\ngini = 0.441\nsamples = 286\nvalue = [192, 94]&#39;),
 Text(0.7528089887640449, 0.4583333333333333, &#39;gini = 0.442\nsamples = 285\nvalue = [191, 94]&#39;),
 Text(0.797752808988764, 0.4583333333333333, &#39;gini = 0.0\nsamples = 1\nvalue = [1, 0]&#39;),
 Text(0.8651685393258427, 0.5416666666666666, &#39;X[0] &lt;= 22.5\ngini = 0.461\nsamples = 861\nvalue = [551, 310]&#39;),
 Text(0.8426966292134831, 0.4583333333333333, &#39;X[0] &lt;= 20.5\ngini = 0.466\nsamples = 666\nvalue = [420, 246]&#39;),
 Text(0.8202247191011236, 0.375, &#39;gini = 0.467\nsamples = 245\nvalue = [154, 91]&#39;),
 Text(0.8651685393258427, 0.375, &#39;X[0] &lt;= 21.5\ngini = 0.465\nsamples = 421\nvalue = [266, 155]&#39;),
 Text(0.8426966292134831, 0.2916666666666667, &#39;gini = 0.465\nsamples = 207\nvalue = [131, 76]&#39;),
 Text(0.8876404494382022, 0.2916666666666667, &#39;gini = 0.466\nsamples = 214\nvalue = [135, 79]&#39;),
 Text(0.8876404494382022, 0.4583333333333333, &#39;gini = 0.441\nsamples = 195\nvalue = [131, 64]&#39;),
 Text(0.8651685393258427, 0.625, &#39;gini = 0.0\nsamples = 3\nvalue = [3, 0]&#39;),
 Text(0.9550561797752809, 0.7083333333333334, &#39;X[0] &lt;= 20.5\ngini = 0.185\nsamples = 29\nvalue = [26, 3]&#39;),
 Text(0.9325842696629213, 0.625, &#39;X[0] &lt;= 19.5\ngini = 0.337\nsamples = 14\nvalue = [11, 3]&#39;),
 Text(0.9101123595505618, 0.5416666666666666, &#39;gini = 0.198\nsamples = 9\nvalue = [8, 1]&#39;),
 Text(0.9550561797752809, 0.5416666666666666, &#39;gini = 0.48\nsamples = 5\nvalue = [3, 2]&#39;),
 Text(0.9775280898876404, 0.625, &#39;gini = 0.0\nsamples = 15\nvalue = [15, 0]&#39;)]
</pre></div>
</div>
<img alt="../_images/decisiontrees_9_1.svg" src="../_images/decisiontrees_9_1.svg" /></div>
</div>
<p>We can plot this same exact model using the graphviz package and we see it looks much better</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graphviz</span>
<span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                                <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_cols</span><span class="p">,</span>  
                                <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  
                      <span class="n">special_characters</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Draw graph</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;svg&quot;</span><span class="p">)</span> 
<span class="n">graph</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/decisiontrees_11_0.svg" src="../_images/decisiontrees_11_0.svg" /></div>
</div>
<p>We can run this exact same decision tree but try to optimize its performance by changing parameters
such as max_depth to set how many layers our tree is able to go until</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="s1">&#39;num_borough&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;NUMBER OF MOTORIST KILLED&#39;</span><span class="p">,</span>
                <span class="s1">&#39;NUMBER OF CYCLIST KILLED&#39;</span><span class="p">,</span>
                <span class="s1">&#39;NUMBER OF PEDESTRIANS KILLED&#39;</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">]</span> <span class="c1"># Features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="o">.</span><span class="n">injury_binary</span> <span class="c1"># Target variable</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span> <span class="c1"># 80% training and 20% test</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Train Decision Tree Classifer</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1">#Predict the response for test dataset</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.6971279373368147
[[1067    0]
 [ 464    1]]
</pre></div>
</div>
</div>
</div>
<p>We can see this change visually by re-running our code to graph the tree</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                                <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_cols</span><span class="p">,</span>  
                                <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  
                                <span class="n">special_characters</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Draw graph</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;svg&quot;</span><span class="p">)</span> 
<span class="n">graph</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/decisiontrees_15_0.svg" src="../_images/decisiontrees_15_0.svg" /></div>
</div>
</div>
<div class="section" id="regression-decision-tree-model">
<h2><span class="section-number">13.2.5. </span>Regression Decision Tree Model<a class="headerlink" href="#regression-decision-tree-model" title="Permalink to this headline">¶</a></h2>
<p>In this example instead of classying a target variable into 0 or 1 we will use a decision tree for regression</p>
<p>The set-up is exactly the same as classification where we select feature columns, a target variable
and split the data into a training and test data set</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> 
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="n">feature_cols2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="s1">&#39;num_borough&#39;</span><span class="p">,</span> 
                 <span class="s1">&#39;NUMBER OF MOTORIST KILLED&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;NUMBER OF CYCLIST KILLED&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;NUMBER OF PEDESTRIANS KILLED&#39;</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="p">[</span><span class="n">feature_cols2</span><span class="p">]</span> <span class="c1"># Features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">nyc_collisions</span><span class="o">.</span><span class="n">num_ppl_injured</span>  <span class="c1">#Target variable</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span> <span class="c1"># 80% training and 20% test</span>
</pre></div>
</div>
</div>
</div>
<p>In a classification problem we can use accuracy and a confusion matrix to gauge a model’s effectiveness but
that is not the case in a regression problem.</p>
<p>Here we use mean absolute error to judge our model</p>
<p>To show what the model is doing, we create another variable for the absolute value of the difference between
the actual and predicted values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rgr</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeRegressor</span><span class="p">()</span>

<span class="c1"># Train Decision Tree Regressor</span>
<span class="n">rgr</span> <span class="o">=</span> <span class="n">rgr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1">#Predict the response for test dataset</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rgr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Actual&#39;</span><span class="p">:</span><span class="n">y_test</span><span class="p">,</span> <span class="s1">&#39;Predicted&#39;</span><span class="p">:</span><span class="n">y_pred</span><span class="p">})</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;diff&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Actual&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Predicted&quot;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;diff&#39;</span><span class="p">],</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean Absolute Error:&#39;</span><span class="p">,</span> 
      <span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean Absolute Error: 0.5601416714129356
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Actual</th>
      <th>Predicted</th>
      <th>diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4880</th>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4058</th>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5954</th>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2226</th>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6532</th>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here we can sort by descending order to show which of our predictions were the worst.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;diff&#39;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Actual</th>
      <th>Predicted</th>
      <th>diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7258</th>
      <td>5</td>
      <td>0.512077</td>
      <td>4.487923</td>
    </tr>
    <tr>
      <th>5363</th>
      <td>5</td>
      <td>0.518293</td>
      <td>4.481707</td>
    </tr>
    <tr>
      <th>1901</th>
      <td>5</td>
      <td>1.000000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>3360</th>
      <td>4</td>
      <td>0.339844</td>
      <td>3.660156</td>
    </tr>
    <tr>
      <th>6313</th>
      <td>4</td>
      <td>0.373596</td>
      <td>3.626404</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Similarly to a classification problem we can still plot the resulting decision tree</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">rgr</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                                <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_cols2</span><span class="p">,</span>  
                                <span class="n">class_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  
                      <span class="n">special_characters</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Draw graph</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;svg&quot;</span><span class="p">)</span> 
<span class="n">graph</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/decisiontrees_23_0.svg" src="../_images/decisiontrees_23_0.svg" /></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="supervised.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">13. </span>Supervised Learning</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="randomforests.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">13.3. </span>Random Forests</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Jun Yan and students in STAT 5255/3255, Spring 2022<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>