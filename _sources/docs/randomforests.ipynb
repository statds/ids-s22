{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1815bc52",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "\n",
    "Random forests are an ensemble learning method that can be used for\n",
    "classification or regression by constructing several individual \n",
    "decision trees as opposed to just one. \n",
    "\n",
    "For classification:\n",
    "\n",
    "- Each decision tree in the forest gives a class prediction, and whichever class is selected most often is the output of the random forest.\n",
    "\n",
    "For regression:\n",
    "\n",
    "- The output of the random forest is the average prediction of the individual trees.\n",
    "\n",
    "Advantages of Random Forests:\n",
    "\n",
    "- Reduces overfitting that sometimes occurs in decision trees and improves accuracy\n",
    "- Can handle large datasets as well as missing data\n",
    "- Can perform both classification and regression tasks\n",
    "- Produces good predictions that can be easily understood\n",
    "\n",
    "Disadvantages of Random Forests:\n",
    "\n",
    "- Requires more computational power and resources\n",
    "- Consumes more time compared to a decision tree algorithm\n",
    "\n",
    "## Installing Packages\n",
    "\n",
    "To utilize random forests in Python, we first need to install the `scikit-learn` package.\n",
    "\n",
    "- pip: `pip install scikit-learn`\n",
    "- conda: `conda install scikit-learn`\n",
    "\n",
    "We'll also want to install the `graphviz` package to improve the visualizations, which can be \n",
    "done using `conda install python-graphviz`.\n",
    "\n",
    "## Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e745b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure the inline figures to svg format\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "## Build a random forest with 50 trees in it\n",
    "clf = RandomForestClassifier(n_estimators = 50, random_state = 99)\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "## Select a single tree from the forest to visualize\n",
    "estimator = clf.estimators_[5]\n",
    "dot_data = tree.export_graphviz(estimator, out_file = None, \n",
    "                                feature_names = wine.feature_names,  \n",
    "                                class_names = wine.target_names,\n",
    "                                filled = True, rounded = True,  \n",
    "                                proportion = False, precision = 2, \n",
    "                                special_characters=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format = \"svg\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd9e37",
   "metadata": {},
   "source": [
    "## Random Forest for Classification Using NYC Crash Data\n",
    "\n",
    "Using the NYC Motor Vehicle Crash data, we'll create a random forest model in order to try and \n",
    "predict whether a crash results in an injury and/or death to any person. Before fitting the model \n",
    "however, we first need to decide which features we'll want to include in our model. For this example, \n",
    "we'll include the following features and outcome variable to predict:\n",
    "\n",
    "- `injured_dead_status` (outcome): indicates whether at least person was injured or killed in a crash (1 = yes, 0 = no)\n",
    "- `timeframe`: the time of day in which the crash occured, split into 6-hour intervals over 24 hours\n",
    "- (1 = 12AM-5:59AM, 2 = 6AM-11:59AM, 3 = 12PM-5:59PM, 4 = 6PM-11:59PM)\n",
    "- `borough`: which borough the crash took place in\n",
    "- `num_vehicles_involved`: number of vehicles involved in a crash\n",
    "- `time_of_week`: day of week of the crash, which we'll split into weekdays and weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f411ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "## Read in NYC crash data\n",
    "nyc_crash = pd.read_csv(\"../data/nyc_mv_collisions_202201.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64aee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new variables relating to people injured and/or killed\n",
    "## in a crash\n",
    "nyc_crash['num_injured_dead'] = nyc_crash.apply(lambda row: \n",
    "                                                   row['NUMBER OF PERSONS KILLED'] +\n",
    "                                                   row['NUMBER OF PERSONS INJURED'],\n",
    "                                                   axis = 1)\n",
    "\n",
    "nyc_crash['injured_dead_status'] = nyc_crash.apply(lambda row:\n",
    "                                                   1 if row['num_injured_dead'] > 0\n",
    "                                                   else 0, axis = 1)\n",
    "\n",
    "nyc_crash['injured_dead_status'] = nyc_crash['injured_dead_status'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fc1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split crash times by hour\n",
    "nyc_crash[\"hour\"] = [x.split(\":\")[0] for x in nyc_crash[\"CRASH TIME\"]]\n",
    "nyc_crash[\"hour\"] = [int(x) for x in nyc_crash[\"hour\"]]\n",
    "\n",
    "def timeframes(x):\n",
    "    if x <= 5:\n",
    "        return 1\n",
    "    elif x > 5 and x <= 11:\n",
    "        return 2\n",
    "    elif x > 11 and x <= 17:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "## Take crash hours and put them into specifc intervals\n",
    "nyc_crash['timeframe'] = nyc_crash['hour'].apply(timeframes)\n",
    "nyc_crash['timeframe'] = nyc_crash['timeframe'].astype('category')\n",
    "\n",
    "contributing_factors = ['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2',\n",
    "                        'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4',\n",
    "                        'CONTRIBUTING FACTOR VEHICLE 5']\n",
    "\n",
    "## Number of vehicles involved in any crash\n",
    "nyc_crash['num_vehicles_involved'] = len(nyc_crash[contributing_factors].columns) - nyc_crash[\n",
    "                                         contributing_factors].isnull().sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert 'CRASH DATE' to datetime format\n",
    "nyc_crash['CRASH DATE'] = nyc_crash['CRASH DATE'].astype('datetime64[ns]')\n",
    "\n",
    "## Column to indicate day of the week\n",
    "nyc_crash['day_of_week'] = nyc_crash['CRASH DATE'].dt.day_name()\n",
    "\n",
    "def is_weekend(x):\n",
    "    if x == 'Saturday' or x == 'Sunday':\n",
    "        return 'weekend'\n",
    "    else:\n",
    "        return 'weekday'\n",
    "    \n",
    "## Categorize days of week to weekday or weekend  \n",
    "nyc_crash['time_of_week'] = nyc_crash['day_of_week'].apply(is_weekend)\n",
    "nyc_crash.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2625f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_crash.rename(columns = {'BOROUGH': 'borough'}, inplace = True)\n",
    "features = nyc_crash[['borough', 'timeframe', 'num_vehicles_involved', 'time_of_week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e76a7",
   "metadata": {},
   "source": [
    "We now have all of the features we want to include in our model. Before we set up our \n",
    "random forest, we'll want to take our caterogical features and transform them into binary \n",
    "data for each category without any arbitrary ordering, a process known as one-hot encoding \n",
    "of data. This can be done very easily in pandas using the `pd.get_dummies()` function, where \n",
    "we pass in our features of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(nyc_crash['injured_dead_status'])\n",
    "features = pd.get_dummies(features)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c861c71",
   "metadata": {},
   "source": [
    "Now our categorical features have seperate columns with binary values for each category. \n",
    "For example, the `borough` variable now has five seperate columns with either a 1 or 0 for \n",
    "each observation, for each borough. Now we can begin building our random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## start building random forest model:\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 42)\n",
    "\n",
    "rfclf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rfclf = rfclf.fit(x_train, y_train)\n",
    "\n",
    "# Extract a single tree from the random forest\n",
    "estimator = rfclf.estimators_[33]\n",
    "dot_data = tree.export_graphviz(estimator, out_file = None, \n",
    "                                feature_names = features.columns,  \n",
    "                                class_names = ['0', '1'],\n",
    "                                filled = True, rounded = True,  \n",
    "                                proportion = False, precision = 2, \n",
    "                                special_characters=True)\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format = \"svg\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ec7b4",
   "metadata": {},
   "source": [
    "This individual decision tree that we selected from the random forest is quite large, with many \n",
    "splits occuring from the top node. If we count the number of levels, we can see that this tree \n",
    "has a depth of 13 before reaching the bottom. For this particular tree, the initial node splits \n",
    "on the `num_vehicles_involved` variable being less than or equal to 1.5 cars. \n",
    "\n",
    "Many of these trees are going to look different, and some might suffer from overfitting or be very \n",
    "inaccurate, but overall the classification returned by the majority of the decision trees is likely \n",
    "to be the most accurate. We can check the accuracy of our random forest model using our test data by \n",
    "using `scikit-learn`'s `accuracy_score()` and `confusion_matrix()` functions. \n",
    "\n",
    "We can also limit the depth of our random forest's trees by passing in the `max_depth` parameter in \n",
    "the random forest classifier, so that it's easier to visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfclf.predict(x_test)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d728558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf2 = RandomForestClassifier(n_estimators = 100, random_state = 42, max_depth = 4)\n",
    "rfclf2 = rfclf2.fit(x_train, y_train)\n",
    "\n",
    "# Extract a single tree from the random forest\n",
    "estimator = rfclf2.estimators_[5]\n",
    "dot_data = tree.export_graphviz(estimator, out_file = None, \n",
    "                                feature_names = features.columns,  \n",
    "                                class_names = ['0', '1'],\n",
    "                                filled = True, rounded = True,  \n",
    "                                proportion = False, precision = 2, \n",
    "                                special_characters=True)\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format = \"svg\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1, 11):\n",
    "    rfclf = RandomForestClassifier(n_estimators = 100, random_state = 42, max_depth = i)\n",
    "    rfclf = rfclf.fit(x_train, y_train)\n",
    "    y_pred = rfclf.predict(x_test)\n",
    "    print(\"Accuracy for Forest with Max Depth {i}:\".format(i = i), \n",
    "          metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67034566",
   "metadata": {},
   "source": [
    "Looking at the depth for the trees in our random forest, it appears that the accuracy of our model \n",
    "is at its highest for trees with a depth between 4 and 6, with an accuracy of about 70.95%. We can\n",
    "also see some other performance metrics using the `classifcation_report()` function in `sckiit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07140aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c99be6",
   "metadata": {},
   "source": [
    "We might also want to take a look at the importance of each of the different features our model\n",
    "considered when splitting on different nodes. This can be done using the `feature_importances_`\n",
    "attribute, which we can plot in a simple bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rfclf.feature_importances_\n",
    "\n",
    "plt.bar(features.columns, importances)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Importance of Each Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920be6e4",
   "metadata": {},
   "source": [
    "## Random Forest Model for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3035b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = labels = np.array(nyc_crash['num_injured_dead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be65e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## start building random forest model:\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels2, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 42)\n",
    "\n",
    "rfclf = RandomForestRegressor(n_estimators = 100, random_state = 42, max_depth = 4)\n",
    "rfclf = rfclf.fit(x_train, y_train)\n",
    "\n",
    "# Extract a single tree from the random forest\n",
    "estimator = rfclf.estimators_[33]\n",
    "dot_data = tree.export_graphviz(estimator, out_file = None, \n",
    "                                feature_names = features.columns,  \n",
    "                                class_names = None,\n",
    "                                filled = True, rounded = True,  \n",
    "                                proportion = False, precision = 2, \n",
    "                                special_characters=True)\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format = \"svg\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfclf.predict(x_test)\n",
    "\n",
    "df = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
    "df[\"diff\"] = abs(df[\"Actual\"] - df[\"Predicted\"])\n",
    "df.sort_values(by = ['diff'], inplace = True)\n",
    "\n",
    "print('Mean Absolute Error:', \n",
    "      metrics.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "df.sort_values(by=['diff'], ascending=False,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaabfb8",
   "metadata": {},
   "source": [
    "## Sources and Additional Information:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "\n",
    "https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76\n",
    "\n",
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "\n",
    "https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c\n",
    "\n",
    "https://www.section.io/engineering-education/introduction-to-random-forest-in-machine-learning/"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.13.7"
   }
  },
  "kernelspec": {
   "display_name": "Anaconda (base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "source_map": [
   12,
   52,
   80,
   96,
   109,
   124,
   152,
   170,
   173,
   181,
   185,
   191,
   211,
   226,
   232,
   249,
   256,
   262,
   264,
   270,
   276,
   280,
   284,
   288,
   310,
   322
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}