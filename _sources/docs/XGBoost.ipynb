{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150962f9",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "XGBoost = Extreme Gradient Boosting. It is an implementation of gradient boosted decision trees. There are many other types of gradient boosting libraries such as Catboost and LightGBM.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. Less feature engineering required (normalizing data and can handle missing values well)\n",
    "2. Feature importance can be seen\n",
    "3. Outliers have minimal impact.\n",
    "4. Handles large sized datasets well.\n",
    "5. Good Execution speed\n",
    "6. Good model performance (wins most of the Kaggle competitions)\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. Visualization can be tough\n",
    "2. Overfitting possible if parameters not tuned properly.\n",
    "3. Harder to tune as there are too many hyperparameters.\n",
    "4. Doesn't easily work with categorical variables\n",
    "\n",
    "## Installing Packages\n",
    "\n",
    "`pip install xgboost` to install\n",
    "\n",
    "Can also use the graphviz package to visualize the trees in the same way we could for decision trees\n",
    "\n",
    "## Data Import and Data Cleaning\n",
    "\n",
    "We have to do a lot of data cleaning in order to add columns that we can use to be able to model easily with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8cce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_crash = pd.read_csv(\"../data/nyc_mv_collisions_202201.csv\")\n",
    "\n",
    "nyc_crash[\"time\"] = [x.split(\":\")[0] for x in nyc_crash[\"CRASH TIME\"]]\n",
    "nyc_crash[\"time\"] = [int(x) for x in nyc_crash[\"time\"]]\n",
    "\n",
    "nyc_crash[\"injury_binary\"] = nyc_crash[\"NUMBER OF PERSONS INJURED\"].map(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "nyc_crash.rename(columns={\"NUMBER OF PERSONS KILLED\": \"num_ppl_killed\"}, inplace=True)\n",
    "nyc_crash.rename(columns={\"NUMBER OF PERSONS INJURED\": \"num_ppl_injured\"}, inplace=True)\n",
    "\n",
    "def seasons(row):\n",
    "    if row['CRASH DATE'] < \"03/20/2021\":\n",
    "        val = \"Winter\"\n",
    "    elif row['CRASH DATE'] < \"06/21/2021\":\n",
    "        val = \"Spring\"\n",
    "    elif row['CRASH DATE'] < \"09/23/2021\":\n",
    "        val = \"Summer\"\n",
    "    elif row['CRASH DATE'] < \"12/21/2021\":\n",
    "        val = \"Autumn\"\n",
    "    else:\n",
    "        val = \"Winter\"\n",
    "    return val\n",
    "\n",
    "nyc_crash['Season'] = nyc_crash.apply(seasons, axis = 1)\n",
    "\n",
    "\n",
    "nyc_crash[\"num_injured\"] = nyc_crash[\"NUMBER OF PEDESTRIANS INJURED\"]\n",
    "nyc_crash[\"num_injured\"] += nyc_crash[\"NUMBER OF CYCLIST INJURED\"]\n",
    "nyc_crash[\"num_injured\"] += nyc_crash[\"NUMBER OF MOTORIST INJURED\"]\n",
    "\n",
    "def injury(row):\n",
    "    if row[\"num_injured\"] >= 1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "nyc_crash['injury'] = nyc_crash.apply(injury, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 1\"] = nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 1\"].fillna('Other')\n",
    "df = nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 1\"].value_counts()\n",
    "\n",
    "def cfv1_1000(row):\n",
    "    if df[row['CONTRIBUTING FACTOR VEHICLE 1']] > 1000:\n",
    "        val = row['CONTRIBUTING FACTOR VEHICLE 1']\n",
    "    else:\n",
    "        val = \"Other\"\n",
    "    return val\n",
    "\n",
    "nyc_crash['cfv1_1000'] = nyc_crash.apply(cfv1_1000, axis = 1)\n",
    "\n",
    "\n",
    "def timeframes(x):\n",
    "    if x <= 5:\n",
    "        return 1\n",
    "    elif x > 5 and x <= 11:\n",
    "        return 2\n",
    "    elif x > 11 and x <= 17:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 2\"] = nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 2\"].fillna('NaN')\n",
    "nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 3\"] = nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 3\"].fillna('NaN')\n",
    "nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 4\"] = nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 4\"].fillna('NaN')\n",
    "nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 5\"] = nyc_crash[\"CONTRIBUTING FACTOR VEHICLE 5\"].fillna('NaN')        \n",
    "\n",
    "def number_of_vehicles(row):\n",
    "    if row[\"CONTRIBUTING FACTOR VEHICLE 5\"] != 'NaN':\n",
    "        val = 5\n",
    "    elif row[\"CONTRIBUTING FACTOR VEHICLE 4\"] != 'NaN':\n",
    "        val = 4\n",
    "    elif row[\"CONTRIBUTING FACTOR VEHICLE 3\"] != 'NaN':\n",
    "        val = 3\n",
    "    elif row[\"CONTRIBUTING FACTOR VEHICLE 2\"] != 'NaN':\n",
    "        val = 2\n",
    "    elif row[\"CONTRIBUTING FACTOR VEHICLE 1\"] != 'NaN':\n",
    "        val = 1\n",
    "    return val\n",
    "\n",
    "nyc_crash['num_vehicles'] = nyc_crash.apply(number_of_vehicles, axis = 1)\n",
    "    \n",
    "\n",
    "## Take crash hours and put them into specifc intervals\n",
    "nyc_crash['timeframe'] = nyc_crash['time'].apply(timeframes)\n",
    "nyc_crash['timeframe'] = nyc_crash['timeframe'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b3c84",
   "metadata": {},
   "source": [
    "## Classification XGBoost Model\n",
    "\n",
    "In this model we are trying to predict if someone was injured or not in the crash. The variables that we will predict it with are the number of vehicles, season, time of day, bourough and the cause of the crash.\n",
    "\n",
    "XGBoost needs a DMatrix to be created in order to run `xgb.train` but we will use the fit function here which accepts a pandas dataframe. A DMatrix can be easily created and it helps to increase memory efficiency and training speed.\n",
    "\n",
    "A DMatrix can be created with `data_dmatrix = xgb.DMatrix(data=,label=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols1 = nyc_crash[['num_vehicles','Season','timeframe', 'BOROUGH', 'cfv1_1000']]\n",
    "features = pd.get_dummies(feature_cols1)\n",
    "\n",
    "y = nyc_crash.injury\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 12)\n",
    "\n",
    "xg_cls = xgb.XGBClassifier(objective ='binary:logistic',seed = 20)\n",
    "\n",
    "xg_cls.fit(x_train,y_train)\n",
    "\n",
    "y_pred = xg_cls.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d11c79",
   "metadata": {},
   "source": [
    "# Tuning the Paramaters - Grid Search\n",
    "\n",
    "An important aspect of XGBoost is tuning the parameters to make the parameters more successful in training the model. One way we can do this is by using Grid Search to search over every combination of specified parameter values and find out which one is the best. \n",
    "\n",
    "There are other ways to find the best parameters but we will just focus on Grid Search here.\n",
    "\n",
    "For this specific example running the actual model only takes seconds but this Grid Search took about 8 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "\n",
    "xgbc = xgb.XGBClassifier(objective ='binary:logistic',seed = 20)\n",
    "\n",
    "clf = GridSearchCV(estimator=xgbc, \n",
    "                   param_grid=params,\n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=1)\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17007d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cls = xgb.XGBClassifier(objective ='binary:logistic',seed = 20,colsample_bytree = .7, learning_rate = .05,\n",
    "                max_depth = 3, n_estimators = 100)\n",
    "\n",
    "xg_cls.fit(x_train,y_train)\n",
    "\n",
    "y_pred = xg_cls.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc77d5",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Here we see how much each variable is affecting the overall prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xgb.plot_importance(xg_cls)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35586d16",
   "metadata": {},
   "source": [
    "## Regression XGBoost Model\n",
    "\n",
    "Almost exactly the same as the classification model except we are predicting the number of people injured instead of if someone was injured. \n",
    "\n",
    "The only difference is we use `xgb.XGBRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "feature_cols2 = nyc_crash[['num_vehicles','Season','timeframe', 'BOROUGH', 'cfv1_1000']]\n",
    "features2 = pd.get_dummies(feature_cols2)\n",
    "\n",
    "y2 = nyc_crash.num_ppl_injured\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=features2,label=y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features2, y2, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 12)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "\n",
    "xg_reg.fit(x_train,y_train)\n",
    "\n",
    "y_pred = xg_reg.predict(x_test)\n",
    "\n",
    "df2=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
    "df2[\"diff\"] = abs(df2[\"Actual\"] - df2[\"Predicted\"])\n",
    "df2.sort_values(by=['diff'], inplace=True)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf789471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(by=['diff'], ascending=False,inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e5882",
   "metadata": {},
   "source": [
    "## Tuning the Parameters - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "xgbr = xgb.XGBRegressor(objective ='reg:squarederror',seed = 20)\n",
    "clf = GridSearchCV(estimator=xgbr, \n",
    "                   param_grid=params,\n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=1)\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.7, learning_rate = 0.01,\n",
    "                max_depth = 3, n_estimators = 500)\n",
    "\n",
    "xg_reg.fit(x_train,y_train)\n",
    "\n",
    "y_pred = xg_reg.predict(x_test)\n",
    "\n",
    "df2=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
    "df2[\"diff\"] = abs(df2[\"Actual\"] - df2[\"Predicted\"])\n",
    "df2.sort_values(by=['diff'], inplace=True)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a48bb3",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d93051",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_reg)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   44,
   50,
   93,
   142,
   151,
   175,
   184,
   205,
   215,
   220,
   226,
   233,
   264,
   267,
   270,
   291,
   307,
   310
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}